{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNsDYMyHz13JfQ/Vx5MVlTf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","import requests\n","import numpy as np\n","import tensorflow as tf\n","from bs4 import BeautifulSoup\n"],"metadata":{"id":"T0VvYXxH84E_","executionInfo":{"status":"ok","timestamp":1718323801912,"user_tz":180,"elapsed":2,"user":{"displayName":"Gustavo Felix","userId":"00728418591549291617"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qyKsJ2Ic8zJc","outputId":"0a8900e8-9df9-437b-80ad-a9ca84fbf34c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","130/130 [==============================] - 157s 1s/step - loss: 6.8079 - accuracy: 0.0492\n","Epoch 2/10\n","130/130 [==============================] - 151s 1s/step - loss: 6.3822 - accuracy: 0.0535\n","Epoch 3/10\n","  6/130 [>.............................] - ETA: 2:44 - loss: 6.3413 - accuracy: 0.0573"]}],"source":["\n","# Exemplo de URL de onde coletar dados\n","url = \"https://pt.wikipedia.org/wiki/Transtornos_do_espectro_autista\"\n","\n","# Enviar requisição HTTP para a URL\n","response = requests.get(url)\n","soup = BeautifulSoup(response.text, 'html.parser')\n","\n","# Coletar parágrafos de texto da página\n","paragraphs = soup.find_all('p')\n","text_data = [para.get_text() for para in paragraphs]\n","\n","# Juntar os parágrafos em um único texto\n","text = ' '.join(text_data)\n","\n","# Salvar o texto coletado em um arquivo\n","with open('arquivoTEA.txt', 'w', encoding='utf-8') as file:\n","    file.write(text)\n","\n","with open('arquivoTEA.txt', 'r', encoding='utf-8') as file:\n","    text = file.read()\n","\n","# Pré-processamento do texto\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([text])\n","total_words = len(tokenizer.word_index) + 1\n","\n","# Criar sequências de entrada e saída\n","input_sequences = []\n","for line in text.split('. '):  # Dividir o texto em sentenças\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequences.append(n_gram_sequence)\n","\n","# Padronizar as sequências\n","max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# Criar inputs e labels\n","xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n","ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n","\n","# Treinamento do modelo\n","model = Sequential()\n","model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n","model.add(LSTM(128, return_sequences=True))\n","model.add(LSTM(64))\n","model.add(Dense(total_words, activation='softmax'))\n","\n","# Compilação do modelo\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Treinamento do modelo\n","model.fit(xs, ys, epochs=10, verbose=1)\n","\n","def responder_pergunta(model, tokenizer, pergunta, max_sequence_len, num_palavras=20):\n","    seed_text = pergunta\n","    for _ in range(num_palavras):\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","        predicted = model.predict(token_list, verbose=0)\n","        predicted_word_index = np.argmax(predicted, axis=-1)[0]\n","\n","        output_word = \"\"\n","        for word, index in tokenizer.word_index.items():\n","            if index == predicted_word_index:\n","                output_word = word\n","                break\n","\n","        seed_text += \" \" + output_word\n","        if output_word == \"\":  # Interrompe se não conseguir prever uma palavra\n","            break\n","\n","    return seed_text\n","\n","# Exemplo de uso\n","pergunta = input(\"Faça uma pergunta: \")\n","resposta = responder_pergunta(model, tokenizer, pergunta, max_sequence_len)\n","print(resposta)\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"lbj8h5Ko83Ze"}}]}